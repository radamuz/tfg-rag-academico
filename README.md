# Asistente RAG â€“ DocumentaciÃ³n tÃ©cnica (TFG)

Asistente conversacional basado en **RAG (Retrieval-Augmented Generation)** para consultar documentaciÃ³n tÃ©cnica/acadÃ©mica en **PDF**, con:

- Ingesta y **troceado** configurable.
- **Indexado versionado** (cada reconstrucciÃ³n crea `data/index/index_YYYYMMDD_HHMMSS`).
- RecuperaciÃ³n por **similitud** o **MMR** (diversidad de fragmentos).
- Respuestas **limitadas al corpus** con **citas** (archivo y pÃ¡gina).
- **UI en Streamlit** con subida de PDFs y control de parÃ¡metros.
- **EvaluaciÃ³n reproducible** (CSV de preguntas + mÃ©tricas).

---

## CaracterÃ­sticas

- Ingesta de PDFs y split configurable (`CHUNK_SIZE`, `CHUNK_OVERLAP`).
- Embeddings con **OpenAI** y almacenamiento en **Chroma** persistente.
- Prompt â€œ**solo con contexto**â€ + listado de **fuentes** (archivo/pÃ¡gina).
- UI: subida de PDFs, sliders de **k** y **temperatura**, botÃ³n **Reconstruir Ã­ndice**.
- Scripts de evaluaciÃ³n: `preguntas.csv` â†’ resultados â†’ mÃ©tricas.

---

## Arquitectura

PDFs (data/raw)
â”‚
â”œâ”€ Ingesta + Split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚
â””â”€ Embeddings (OpenAI) â†’ Chroma â†â”€â”€â”€â”˜ (Ã­ndice versionado)
â”‚
RecuperaciÃ³n (Sim / MMR)
â”‚
Prompt estructurado + LLM
â”‚
Respuesta + Citas a pÃ¡gina

---

## Requisitos

- **Python 3.10+** (Windows/macOS/Linux).
- Cuenta de **OpenAI** con **API key** y crÃ©dito activo.

---

## Estructura

app/ # config, ingest, index, rag
ui/ # app_streamlit.py (Streamlit)
eval/ # preguntas.csv, run_eval.py, metricas.py
data/
raw/ # PDFs (no se suben)
processed/# preview opcional
index/ # Ã­ndices versionados (no se suben)
scripts/ # run_ui.cmd, reindex.cmd, etc.
.env.example
.gitignore
requirements.txt
requirements_lock.txt
LICENSE
README.md

---

## ğŸ§© InstalaciÃ³n

### OpciÃ³n A (normal, recomendada)

```bat
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
copy .env.example .env   & rem aÃ±ade tu OPENAI_API_KEY

python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements_lock.txt
copy .env.example .env   & rem aÃ±ade tu OPENAI_API_KEY

```

## Uso

1. Indexar (con PDFs en data/raw/)
   python -m app.index

Crea data/index/index_YYYYMMDD_HHMMSS.

2. Lanzar la UI
   python -m streamlit run ui/app_streamlit.py

Sube PDFs desde la propia UI (se guardan en data/raw/).

Ajusta k y temperatura; activa MMR si quieres mÃ¡s diversidad.

Usa Reconstruir Ã­ndice tras subir/aÃ±adir PDFs.

## EvaluaciÃ³n

Edita eval/preguntas.csv (id,pregunta).

Ejecuta:

python eval\run_eval.py

â†’ genera eval/resultados_YYYYMMDD_HHMMSS.csv con respuesta, tiempo y fuentes. 3) MÃ©tricas:

python eval\metricas.py

â†’ muestra % de acierto (exacto/parcial) y tiempo medio (detecta el Ãºltimo CSV).

## ConfiguraciÃ³n (.env)

OPENAI_API_KEY=sk-proj-XXXXXXXXXXXX
DEFAULT_EMBED_MODEL=text-embedding-3-small
DEFAULT_CHAT_MODEL=gpt-4.1-mini
CHUNK_SIZE=1200
CHUNK_OVERLAP=200

---

## Capturas

![UI principal](docs/ui_home.png)
![Respuesta con citas](docs/ui_answer.png)
![Subida e indexado](docs/ui_upload.png)

---

## Buenas prÃ¡cticas

Empezar con k=4, MMR activado, temperature=0.1.

Medir: tiempo medio, % preguntas resueltas y calidad de citas.

Ajustar chunking segÃºn el tipo de documento (tablas, guÃ­as largas, etc.).

---

## SoluciÃ³n de problemas

ModuleNotFoundError â†’ activa el venv y reinstala:
.\.venv\Scripts\activate
pip install -r requirements.txt
429 / quota exceeded â†’ revisa Billing en OpenAI.

WinError 32 al reindexar â†’ cierra la UI (libera data/index/) y vuelve a ejecutar python -m app.index.
PDFs no aparecen â†’ verifica que estÃ¡n en data/raw/ y pulsa â€œReconstruir Ã­ndiceâ€.
Texto con caracteres raros â†’ guarda los .py en UTF-8.
streamlit no se reconoce â†’ ejecuta con:
python -m streamlit run ui/app_streamlit.py

---

## Licencia

Este proyecto se distribuye bajo licencia MIT. Ver LICENSE

---

## CrÃ©ditos

Autor: Cristian (FingFangFung)
Stack: Python, LangChain, OpenAI, ChromaDB, Streamlit.
